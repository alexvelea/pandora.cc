\chapter{Framework Overview}

This chapter tries to present a brief overview of what the library does and showcase some use cases as well as the motivation behind it. The contents of this chapter are optional, but it'll help to put things in a better perspective as we dive into various comparisons and implementations.

\section{Motivation}

\subsection*{State of the art} With the developments in the CPU world, high-level languages became more and more popular since the majority of the users could offer the required computing speed to overcome the overhead of such languages. In recent years this trend gained traction in the service world as well. Developers started opting for server-side code in Python or Node.js, which would require more servers or deliver worse latency in very sensitive cases. The majority of these arguments are usually countered by the fact that the cost of developing in higher-level languages is much higher than the cost of the extra hardware required.

\subsection*{History} Having some experience with parallel programming, the first big project served an essential roll in discovering the pitfalls and benefits of different practices along with various implications which can't be easily quantified, as development speed, code maintainability cost, and complexity for users which are not familiar with the codebase into the point where they are able to contribute.

The need for parallelism raised as a necessity to make the code faster, opting for vertical scaling in order to maximize the throughput. Due to the design of the application, some components couldn't be parallelized, yielding a codebase where the flow of a request was partially parallelized to increase the response time. Since most parallel programming libraries added a substantial overhead of communication, they couldn't be used in order to decrease the time of a specific request. Due to this context, we opted for a low-level option, a thread-pool. This seemed like the best way to reduce overhead and write little bloatware. But in time, the complexity of the code increased, and the tasks being run in the thread-pools became chaotic really quick. This made the code really hard to follow and to synchronize. The first alternative to the problem was to use something similar to the microservices architecture, and with some digging, the nanoservices resurfaced as a viable solution.

\subsection*{Solution} Pandora.cc started out with the simple idea to offer a fast way for nanoservices to communicate, thus C++ being the language of choice. The target is to take function calls and run them on a different thread while being able to retrieve the result in a practical way while having some control over which hardware components it runs so it'll reduce the number of synchronization mechanisms required. The first part could've been easily achieved using std::future and std:: async, both being available in the standard library of C++. The problem was that they were too slow, thus increasing the desire for such a library. In time, the idea to make function calls to other threads evolved in making these calls to another computer altogether, all of these details being taken care of the framework, while someone looking at the code couldn't determine if the service call would be run on the same server or not.

\section{What it does}
Pandora.cc enables the development of applications using nanoservices as its primitive computational unit while highly rewarding having a good application architectural structures. These nanoservices benefit from a fast message mailbox while communicating on the same server, i.e., when no network call is involved. This allows them to become fast, maintainable, and easy to develop a way to express code.

To an outside user, Pandora applications look similar to applications that follow a 'less regulated' actor model due to its odd development practices. While this may be the case, the code is enforced to be more structured and to address data-sharing accordingly. After the development of the code, an unusual step arises, in the development of how the nanoservices will be run inside a Pandora application.

Developing a good architecture regarding how nanoservices should run on a service is a critical step when using Pandora. This is done using the bundle system. The bundle system allows for bundling of different nanoservices which are used together to form a microservice.
Such an example can be a FileBundle, which consists of FetchFile, ProcessFile, and SaveFile. While these nanoservices are generally used together, they will benefit from being able to run in parallel, and, if run on the same server, the communication overhead becomes negligible. The memory transfer is equivalent to copying an object inside the server's RAM while the framework reduces the latency for each call, being able to achieve $10^6$ sequential calls between a pair of services (a → b → a → b …).

Nanoservice thread specification is also achieved throw the bundling system. While specifying for each nanoservice how many replicas(running instances) should an application run, it's also possible to specify on which CPU threads this should happen. In this way, it's possible to share memory between nanoservices through a global state which does not require any synchronization mechanisms if done right. For example, 2 nanoservices SetValue and GetValue can be configured to be able to run on the same thread for lock-free code. Another use case is represented by nanoservices, which are hardware bound, like FetchFile and SaveFile. If both of these nanoservices ran in parallel, it would not speed up the process since the bottleneck is represented by the SDD/HDD, not the CPU. Service prioritization is another aspect to keep in mind since it can allow some latency-sensitive services always to have a free thread waiting for them so the task can start at once. 

Distributed programming becomes available just by writing some config files. The nanoservice calls are unaware if they will be processed on this server or somewhere in the cloud. When deploying another Pandora binary, it'll automatically broadcast its list of available nanoservices endpoints to all other binaries in the network, via a service discovery process.
Target use cases
High-performance applications. Due to it's fast and customizable parallelism model, Pandora.cc can be successfully used as a viable option for developing single-server apps that require high thruput and can benefit from using multiple CPU-cores. Such examples can include stock-trading apps or cryptocurrency algorithm implementations that use proof of stake.

First framework for small applications. Due to the API of Pandora.cc, it's easy to migrate if needed to another parallel or distributed framework since the majority of the code could be salvaged with ease. This is backed up by the fact that the code is written with minimum glue-code, and the user is not tied in some technologies and can easily switch to a more classic microservices framework, like using Google's RPC framework along with protobuf.

Future scalability. While most projects start without a defined idea in mind and can find themselves in a tight spot due to limitations to enter horizontal scaling, Pandora.cc enables this by design while trying to protect developers from harmful practices. This is a crucial decision to make before choosing the framework since the majority of applications would not require vast resources, but this can become a reality in case of a surge in the number of users or just organic growth. Usually, this can have bad implications, which can be found especially in applications that follow the Monolithic Architecture pattern, where developers find themselves refactoring a lot of time at once, trying to make the codebase scalable.

Fast scalability. While all microservice-based systems offer unlimited horizontal scalability by design, Pandora.cc tries to offer fast on-demand scalability as well. Some applications might require a boost in a specific service from time to time, due to special events such as sales or holidays. Such an example would be Black Friday when online shops would require to add more services that would serve products that a user might want to buy based on past purchases or currently opened pages. This can be done using Pandora.cc without codebase changes or changing configs for current-running services.


\section{Target use cases}

\begin{itemize}
\item \textbf{High-performance applications} Due to it's fast and customisable parallelism model, Pandora.cc can be succesfully used as a viable option for developing single-server apps which require high thruput and can benefit from using multiple CPU-cores. Such examples can include stock-trading apps or crypto currency algorithm implementations which use proof of stake.

\item \textbf{First framework for small applications} Due to the API of Pandora.cc, it's easy to migrate if needed to another parallel or distributed framework since the majority of the code could be salvaged with ease. This is backed up by the fact that the code is written with minimum glue-code and the user is not tied in some technologies and can easely switch to more clasic microservices framework, like using Google's RPC framework along with protobuffers.

\item \textbf{Future scalability} While most projects start without a defined idea in mind and can find themselves in a tight spot due to limitations to enter horizontal scaling, Pandora.cc enables this by design while trying to protect developers from bad practices. This is an important decision to make before choosing the framework since the majority of applications whould not require huge resources but this can become reality in case of a surge in the number of users or just organic growth. Usually this can have bad implications which can be found especially in applications which follow the Monolithic Architecture pattern, where developers find themselves refactoring a lot of time at once trying to make the codebase scalable.

\item \textbf{Fast scalability} While all microservice-based systems offer unlimited horizontal scalability by design, Pandora.cc tries to offer fast on-demand scalability as well. Some applications might require a boost in a specific service from time to time, due to special events such as sales or holidays. Such an example would be Black Friday, when online shops would require to add more services which would serve products that a user might want to buy based on past purchases or current opened pages. This can be done using pandora.cc without codebase changes or changing configs for current-running services.
\end{itemize}
